{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabonoid/etl-pyspark-basico/blob/main/etl_articulo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmtU-a_47e85"
      },
      "source": [
        "# **ETL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDpgDzDxC7jl"
      },
      "source": [
        "Empezaremos creando nuestros directorios donde se va almacenar la mayoria de nuestros archivos.\n",
        "Tendremos la siguiente estructura:\n",
        "- `/content/pdf/`\n",
        "- `/content/zip/`\n",
        "- `/content/csv/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQZRpDQqC6rR",
        "outputId": "bb55d2e6-ad3e-4414-e672-5663184447d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directorio '/content/pdf' creado exitosamente.\n",
            "Directorio '/content/zip' creado exitosamente.\n",
            "Directorio '/content/csv' creado exitosamente.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "base_path = \"/content/\"\n",
        "directorios = [\"pdf\", \"zip\", \"csv\"]\n",
        "\n",
        "for directorio in directorios:\n",
        "    ruta_directorio = os.path.join(base_path, directorio)\n",
        "    os.makedirs(ruta_directorio, exist_ok=True)\n",
        "    print(f\"Directorio '{ruta_directorio}' creado exitosamente.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIESYS_x7kf9"
      },
      "source": [
        "## **Extract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4Uz_rEIE67P"
      },
      "source": [
        "Empezaremos por descargar los PDF donde estan todos los links de descarga"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkRXuEz3E5Fw"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "def descargar_url(url, destino):\n",
        "    # Extrae el nombre del archivo de la URL\n",
        "    nombre_archivo = os.path.basename(url)\n",
        "\n",
        "    # Realiza la solicitud GET al enlace\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Verifica si la solicitud fue exitosa (código de estado 200)\n",
        "    if response.status_code == 200:\n",
        "        # Abre el archivo en modo escritura binaria ('wb')\n",
        "        with open(destino + nombre_archivo, 'wb') as file:\n",
        "            # Escribe el contenido del archivo en el archivo local\n",
        "            file.write(response.content)\n",
        "        print(f\"Archivo {nombre_archivo} descargado correctamente.\")\n",
        "    else:\n",
        "        print(\n",
        "            f\"Error al descargar el archivo desde {url}. \\\n",
        "            Código de estado: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhunVqSZGfdb",
        "outputId": "ebc70143-9fe3-4a55-a644-5453cc3f4b9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo Cierre_Datos_abiertos_hist_ricos_2020.pdf descargado correctamente.\n",
            "Archivo Cierre_Datos_abiertos_historicos_2021.pdf descargado correctamente.\n",
            "Archivo cierre_covid19__2022.pdf descargado correctamente.\n",
            "Archivo datos_abiertos_historicos_2023.pdf descargado correctamente.\n",
            "Archivo datos_abiertos_historicos_2024.pdf descargado correctamente.\n"
          ]
        }
      ],
      "source": [
        "pdf_url = ['https://www.gob.mx/cms/uploads/attachment/file/753710/Cierre_Datos_abiertos_hist_ricos_2020.pdf',\n",
        "           'https://www.gob.mx/cms/uploads/attachment/file/753711/Cierre_Datos_abiertos_historicos_2021.pdf',\n",
        "           'https://www.gob.mx/cms/uploads/attachment/file/830686/cierre_covid19__2022.pdf',\n",
        "           'https://www.gob.mx/cms/uploads/attachment/file/891414/datos_abiertos_historicos_2023.pdf',\n",
        "           'https://www.gob.mx/cms/uploads/attachment/file/914275/datos_abiertos_historicos_2024.pdf']\n",
        "\n",
        "for pdf in pdf_url:\n",
        "    descargar_url(pdf, '/content/pdf/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yr2-iOyq70vK",
        "outputId": "b933aa7f-75bc-4401-c2fc-d13a4ea47f7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/232.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N05Q5ah9-Z83"
      },
      "source": [
        "Como primer paso dentro del **Extract** es obtener todos los links de descargas de nuestros CSV. Estos links de descarga se encuentran dentro de PDF, un PDF para cada año. Con la libreia PyPDF2 lo que hacemos es leer estos PDF y leer todos los hipervinculos que se encuentran dentro.\n",
        "Posteriormente creamos un txt con todos los links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXs9req57nZU"
      },
      "outputs": [],
      "source": [
        "import PyPDF2\n",
        "\n",
        "\n",
        "def nombres_archivos(carpeta):\n",
        "    # Lista para almacenar los nombres de archivos\n",
        "    nombres_archivos = []\n",
        "    # Itera sobre los archivos en la carpeta\n",
        "    for nombre_archivo in os.listdir(carpeta):\n",
        "        # Verifica si el nombre representa un archivo (no una subcarpeta)\n",
        "        if os.path.isfile(os.path.join(carpeta, nombre_archivo)):\n",
        "            nombres_archivos.append(nombre_archivo)\n",
        "    return nombres_archivos\n",
        "\n",
        "\n",
        "def obtener_hipervinculos(path):\n",
        "    # Abre el archivo PDF en modo lectura binaria\n",
        "    with open(f'/content/pdf/{path}', 'rb') as file:\n",
        "        # Crea un objeto PdfReader\n",
        "\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "\n",
        "        # Itera sobre cada página del PDF\n",
        "        for page_num in range(len(reader.pages)):\n",
        "            # Obtiene el objeto de página actual\n",
        "            page = reader.pages[page_num]\n",
        "\n",
        "            # Busca en los recursos de la página los enlaces\n",
        "            if '/Annots' in page:\n",
        "                for annot in page['/Annots']:\n",
        "                    annotation_object = annot.get_object()\n",
        "                    if '/A' in annotation_object:\n",
        "                        if annotation_object['/A']['/S'] == '/URI':\n",
        "                            with open('/content/links.txt', 'a') as archivo:\n",
        "                                # Escribe el string en el archivo\n",
        "                                # Agrega un salto de línea al final\n",
        "                                archivo.write(\n",
        "                                    annotation_object['/A']['/URI'] + '\\n')\n",
        "\n",
        "\n",
        "# Lista para almacenar los nombres de archivos\n",
        "nombres_pdf = nombres_archivos('/content/pdf')\n",
        "\n",
        "for nombre in nombres_pdf:\n",
        "    obtener_hipervinculos(nombre)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRGEUuCA_GcZ"
      },
      "source": [
        "Ya una vez obtenido nuestros links procedemos a descargar cada uno de los links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF-ic2Px_OM_",
        "outputId": "de6e4faf-10a8-4e33-e85a-7166e59ccad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo datos_abiertos_covid19_02.04.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_09.04.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_16.04.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_23.04.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_30.04.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_05.03.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_12.03.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_19.03.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_26.03.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_06.02.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_13.02.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_20.02.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_27.02.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_02.01.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_09.01.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_16.01.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_23.01.2024.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_30.01.2024.zip descargado correctamente.\n",
            "Archivo COVID19MEXICO2020.zip descargado correctamente.\n",
            "Archivo COVID19MEXICO2022.zip descargado correctamente.\n",
            "Archivo COVID19MEXICO2021.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_05.12.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_12.12.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_19.12.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_26.12.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_07.11.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_14.11.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_21.11.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_28.11.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_03.10.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_10.10.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_17.10.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_24.10.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_31.10.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_05.09.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_12.09.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_19.09.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_26.09.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_01.08.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_08.08.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_15.08.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_22.08.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_29.08.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_04.07.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_11.07.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_18.07.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_25.07.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_06.06.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_13.06.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_20.06.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_27.06.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_02.05.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_09.05.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_17.05.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_23.05.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_30.05.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_04.04.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_11.04.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_18.04.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_25.04.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_07.03.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_14.03.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_21.03.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_28.03.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_07.02.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_14.02.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_21.02.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_28.02.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_03.01.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_10.01.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_17.01.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_24.01.2023.zip descargado correctamente.\n",
            "Archivo datos_abiertos_covid19_31.01.2023.zip descargado correctamente.\n"
          ]
        }
      ],
      "source": [
        "with open('/content/links.txt', 'r') as archivo:\n",
        "    for linea in archivo:\n",
        "        descargar_url(linea.strip(), '/content/zip/')\n",
        "\n",
        "# descargar_url('https://datosabiertos.salud.gob.mx/gobmx/salud/datos_abiertos/historicos/2020/COVID19MEXICO2020.zip', '/content/zip/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8XQ5Jr-AsXT"
      },
      "source": [
        "En nuestro directorio `/content/zip` hemos guardado todos los archivos ZIP, procedemos a descomprimir cada uno."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbYJnGTCBOsO"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "\n",
        "def descomprimir_zip(name, archivo_zip, directorio_destino):\n",
        "    # Abre el archivo ZIP en modo lectura\n",
        "    with zipfile.ZipFile(archivo_zip, 'r') as zip_ref:\n",
        "            # Extrae todos los archivos en el directorio especificado\n",
        "            zip_ref.extractall(directorio_destino)\n",
        "            nombres_archivos_extraidos = zip_ref.namelist()\n",
        "            # Renombra el directorio descomprimido con el nombre del archivo original\n",
        "            os.rename(\n",
        "                f'/content/csv/{nombres_archivos_extraidos[-1]}',\n",
        "                f'/content/csv/{name.replace(\".zip\", \".csv\")}')\n",
        "\n",
        "\n",
        "# Ruta del archivo ZIP que deseas descomprimir\n",
        "archivos_zip = nombres_archivos('/content/zip')\n",
        "\n",
        "# Directorio donde deseas descomprimir los archivos\n",
        "directorio_destino = '/content/csv'\n",
        "\n",
        "\n",
        "for archivo in archivos_zip:\n",
        "    archivo_zip = f'/content/zip/{archivo}'\n",
        "    # Llama a la función para descomprimir el archivo ZIP\n",
        "    descomprimir_zip(archivo, archivo_zip, directorio_destino)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1Gt7wi1CUkT"
      },
      "source": [
        "Hemos extraido con exito todos los CSV dando fin al paso de extracción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWZJ_UwvN0MC"
      },
      "outputs": [],
      "source": [
        "# Itera sobre los archivos y directorios en el directorio\n",
        "for elemento in os.listdir(\"/content/csv\"):\n",
        "    ruta_elemento = os.path.join(directorio, elemento)\n",
        "\n",
        "    # Si es un archivo, verifica si es un archivo CSV\n",
        "    if os.path.isfile(ruta_elemento):\n",
        "        if not elemento.endswith('.csv'):\n",
        "            os.remove(ruta_elemento)\n",
        "\n",
        "    # Si es un directorio, elimínalo recursivamente\n",
        "    elif os.path.isdir(ruta_elemento):\n",
        "        os.removedirs(ruta_elemento)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--5nSk1SCmet"
      },
      "source": [
        "## **Transform**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH8JoLk5Pq89"
      },
      "source": [
        "Hemos entrado ya a la parte de transformacion de los datos. Es aqui donde aplicaremos todos los filtros para limpiar y/o ordenar nuestros datos.\n",
        "Vamos a utilizar Spark para este apartado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpzyFTCVWTAg",
        "outputId": "376dcd05-f158-45d3-9d32-b5ca8d81b58e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=2a9eb0d88a217019e846faabaae2d71f3040867936d371486c3ec32c2c723c50\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtzgAEQaWXed"
      },
      "source": [
        "Como todo proyecto de spark empezaremos por crear unestro `SparkSession` y nuestro `sparkContext`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzxFnXpCWVeD"
      },
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .appName(\"ETL_basico_BigData\") \\\n",
        "        .getOrCreate()\n",
        "\n",
        "sc = spark.sparkContext\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl2I0no-EQDY",
        "outputId": "f0b7058f-adf8-41ec-9e00-43d8a66d34ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-> datos_abiertos_covid19_22.08.2023.csv\n",
            "2-> datos_abiertos_covid19_06.02.2024.csv\n",
            "3-> datos_abiertos_covid19_08.08.2023.csv\n",
            "4-> datos_abiertos_covid19_04.04.2023.csv\n",
            "5-> datos_abiertos_covid19_30.01.2024.csv\n",
            "6-> datos_abiertos_covid19_16.01.2024.csv\n",
            "7-> datos_abiertos_covid19_02.04.2024.csv\n",
            "8-> datos_abiertos_covid19_13.06.2023.csv\n",
            "9-> datos_abiertos_covid19_18.04.2023.csv\n",
            "10-> datos_abiertos_covid19_28.02.2023.csv\n",
            "11-> datos_abiertos_covid19_24.01.2023.csv\n",
            "12-> datos_abiertos_covid19_16.04.2024.csv\n",
            "13-> datos_abiertos_covid19_17.01.2023.csv\n",
            "14-> datos_abiertos_covid19_14.03.2023.csv\n",
            "15-> datos_abiertos_covid19_15.08.2023.csv\n",
            "16-> datos_abiertos_covid19_11.04.2023.csv\n",
            "17-> datos_abiertos_covid19_23.04.2024.csv\n",
            "18-> datos_abiertos_covid19_21.11.2023.csv\n",
            "19-> datos_abiertos_covid19_13.02.2024.csv\n",
            "20-> datos_abiertos_covid19_09.05.2023.csv\n",
            "21-> datos_abiertos_covid19_07.11.2023.csv\n",
            "22-> datos_abiertos_covid19_23.05.2023.csv\n",
            "23-> datos_abiertos_covid19_28.03.2023.csv\n",
            "24-> datos_abiertos_covid19_21.02.2023.csv\n",
            "25-> datos_abiertos_covid19_26.12.2023.csv\n",
            "26-> datos_abiertos_covid19_20.02.2024.csv\n",
            "27-> datos_abiertos_covid19_26.09.2023.csv\n",
            "28-> datos_abiertos_covid19_30.04.2024.csv\n",
            "29-> datos_abiertos_covid19_27.06.2023.csv\n",
            "30-> datos_abiertos_covid19_25.04.2023.csv\n",
            "31-> datos_abiertos_covid19_24.10.2023.csv\n",
            "32-> datos_abiertos_covid19_20.06.2023.csv\n",
            "33-> datos_abiertos_covid19_03.10.2023.csv\n",
            "34-> datos_abiertos_covid19_19.03.2024.csv\n",
            "35-> datos_abiertos_covid19_06.06.2023.csv\n",
            "36-> datos_abiertos_covid19_31.10.2023.csv\n",
            "37-> datos_abiertos_covid19_26.03.2024.csv\n",
            "38-> datos_abiertos_covid19_04.07.2023.csv\n",
            "39-> datos_abiertos_covid19_17.10.2023.csv\n",
            "40-> datos_abiertos_covid19_10.01.2023.csv\n",
            "41-> datos_abiertos_covid19_02.05.2023.csv\n",
            "42-> datos_abiertos_covid19_05.09.2023.csv\n",
            "43-> datos_abiertos_covid19_14.11.2023.csv\n",
            "44-> datos_abiertos_covid19_21.03.2023.csv\n",
            "45-> datos_abiertos_covid19_23.01.2024.csv\n",
            "46-> datos_abiertos_covid19_30.05.2023.csv\n",
            "47-> datos_abiertos_covid19_05.12.2023.csv\n",
            "48-> datos_abiertos_covid19_07.02.2023.csv\n",
            "49-> datos_abiertos_covid19_14.02.2023.csv\n",
            "50-> datos_abiertos_covid19_31.01.2023.csv\n",
            "51-> datos_abiertos_covid19_18.07.2023.csv\n",
            "52-> datos_abiertos_covid19_19.12.2023.csv\n",
            "53-> COVID19MEXICO2022.csv\n",
            "54-> datos_abiertos_covid19_07.03.2023.csv\n",
            "55-> datos_abiertos_covid19_03.01.2023.csv\n",
            "56-> datos_abiertos_covid19_12.03.2024.csv\n",
            "57-> datos_abiertos_covid19_01.08.2023.csv\n",
            "58-> datos_abiertos_covid19_12.09.2023.csv\n",
            "59-> datos_abiertos_covid19_05.03.2024.csv\n",
            "60-> datos_abiertos_covid19_09.04.2024.csv\n",
            "61-> datos_abiertos_covid19_02.01.2024.csv\n",
            "62-> datos_abiertos_covid19_11.07.2023.csv\n",
            "63-> datos_abiertos_covid19_09.01.2024.csv\n",
            "64-> COVID19MEXICO2021.csv\n",
            "65-> datos_abiertos_covid19_19.09.2023.csv\n",
            "66-> datos_abiertos_covid19_17.05.2023.csv\n",
            "67-> datos_abiertos_covid19_27.02.2024.csv\n",
            "68-> datos_abiertos_covid19_12.12.2023.csv\n",
            "69-> datos_abiertos_covid19_10.10.2023.csv\n",
            "70-> datos_abiertos_covid19_25.07.2023.csv\n",
            "71-> COVID19MEXICO2020.csv\n",
            "72-> datos_abiertos_covid19_28.11.2023.csv\n",
            "73-> datos_abiertos_covid19_29.08.2023.csv\n"
          ]
        }
      ],
      "source": [
        "for i, archivo in enumerate(nombres_archivos('/content/csv')):\n",
        "\n",
        "    with open(f'/content/csv/{archivo}', 'r', encoding='utf-8') as entrada:\n",
        "        contenido = entrada.read()\n",
        "\n",
        "    contenido_sin_comillas = contenido.replace(\n",
        "        'Países de la Ex-U.R.S.S., excepto Ucrania y Bielorusia', 'Países de la Ex-U.R.S.S. excepto Ucrania y Bielorusia')\n",
        "\n",
        "    with open(f'/content/csv/{archivo}', 'w', encoding='utf-8') as salida:\n",
        "        salida.write(contenido_sin_comillas)\n",
        "\n",
        "    print(f\"{i+1}-> {archivo}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2aRHaSAXTcr"
      },
      "source": [
        "En pasos anteriores hemos descargado los csv, utilizando spark vamos a unificar estos CSV para convertirlo en un solo dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSmnPpUrXnnR"
      },
      "outputs": [],
      "source": [
        "# Obtenemos los nombres de los ficheros dentro de nuestro directorio csv\n",
        "csv_covid = nombres_archivos('/content/csv/')\n",
        "# Hacemos un dataframe unificado\n",
        "df = spark.read.option(\"header\", \"true\")\\\n",
        "    .csv(list(map(lambda x: \"/content/csv/\" + x, csv_covid)),\n",
        "         encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmxvrwDgjAWP"
      },
      "source": [
        "### **Visualizacion los de Datos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7bSDhpVarp3"
      },
      "source": [
        "Checamos cuantos datos tenemos en nuestro dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMlN_UUca1gE",
        "outputId": "746384bc-44f2-426e-abe7-8c1450be476b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "227757980"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36X5Mh5scJ1I",
        "outputId": "878e3354-9cd0-40d0-897e-2baa9a98cb3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
            "|FECHA_ACTUALIZACION|ID_REGISTRO|ORIGEN|SECTOR|ENTIDAD_UM|SEXO|ENTIDAD_NAC|ENTIDAD_RES|MUNICIPIO_RES|TIPO_PACIENTE|FECHA_INGRESO|FECHA_SINTOMAS| FECHA_DEF|INTUBADO|NEUMONIA|EDAD|NACIONALIDAD|EMBARAZO|HABLA_LENGUA_INDIG|INDIGENA|DIABETES|EPOC|ASMA|INMUSUPR|HIPERTENSION|OTRA_COM|CARDIOVASCULAR|OBESIDAD|RENAL_CRONICA|TABAQUISMO|OTRO_CASO|TOMA_MUESTRA_LAB|RESULTADO_LAB|TOMA_MUESTRA_ANTIGENO|RESULTADO_ANTIGENO|CLASIFICACION_FINAL|MIGRANTE|PAIS_NACIONALIDAD|PAIS_ORIGEN|UCI|\n",
            "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
            "|         2023-08-22|     0ed066|     2|    12|        16|   2|         16|         16|          041|            1|   2023-03-09|    2023-03-06|9999-99-99|      97|       2|  28|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         1|        2|               2|           97|                    1|                 2|                  7|      99|           México|         97| 97|\n",
            "|         2023-08-22|     c92b92|     1|    12|        07|   2|         07|         07|          101|            1|   2023-02-22|    2023-02-20|9999-99-99|      97|       2|  24|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|           México|         97| 97|\n",
            "|         2023-08-22|     db9c89|     2|    12|        07|   1|         07|         07|          108|            1|   2023-01-19|    2023-01-16|9999-99-99|      97|       2|  28|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|           México|         97| 97|\n",
            "|         2023-08-22|     a5442c|     2|    12|        09|   1|         09|         09|          004|            1|   2023-01-12|    2023-01-12|9999-99-99|      97|       2|   5|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    1|                 2|                  7|      99|           México|         97| 97|\n",
            "|         2023-08-22|     dacb2c|     2|    12|        07|   1|         07|         07|          108|            1|   2023-01-19|    2023-01-16|9999-99-99|      97|       2|  45|           1|       2|                 2|       2|       2|   2|   2|       2|           1|       2|             2|       1|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|           México|         97| 97|\n",
            "|         2023-08-22|     6cef7b|     2|    12|        07|   1|         07|         07|          108|            1|   2023-01-16|    2023-01-14|9999-99-99|      97|       2|  54|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               2|           97|                    2|                97|                  6|      99|           México|         97| 97|\n",
            "|         2023-08-22|     dcee4a|     1|     6|        11|   1|         11|         11|          020|            1|   2023-03-25|    2023-03-22|9999-99-99|      97|       2|  62|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               2|           97|                    1|                 1|                  3|      99|           México|         97| 97|\n",
            "|         2023-08-22|     6236e4|     2|    12|        09|   2|         09|         09|          009|            1|   2023-01-23|    2023-01-23|9999-99-99|      97|       2|  40|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        1|               2|           97|                    1|                 1|                  3|      99|           México|         97| 97|\n",
            "|         2023-08-22|     e7e34b|     2|    12|        09|   2|         15|         15|          025|            1|   2023-01-13|    2023-01-13|9999-99-99|      97|       2|   7|           1|      97|                 2|       2|       2|   2|   2|       2|           2|       2|             2|       2|            2|         2|        2|               1|            2|                    2|                97|                  7|      99|           México|         97| 97|\n",
            "|         2023-08-22|     7aeb5d|     2|    12|        03|   1|         15|         03|          003|            1|   2023-06-12|    2023-06-09|9999-99-99|      97|       2|  77|           1|       2|                 2|       2|       2|   2|   2|       2|           2|       2|             1|       2|            2|         2|        1|               2|           97|                    1|                 2|                  7|      99|           México|         97| 97|\n",
            "+-------------------+-----------+------+------+----------+----+-----------+-----------+-------------+-------------+-------------+--------------+----------+--------+--------+----+------------+--------+------------------+--------+--------+----+----+--------+------------+--------+--------------+--------+-------------+----------+---------+----------------+-------------+---------------------+------------------+-------------------+--------+-----------------+-----------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRaNeXB8Qfel"
      },
      "source": [
        "### **Limpieza de Datos**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErvVXMyGjDe6"
      },
      "source": [
        "Damos comienzo a la limpieza de los datos cambiando el formato de la fecha. Primero tenemos que analizar cuantos tipos de formatos de fechas contiene nuestro DataSet ya que estos vienen variados.\n",
        "\n",
        "En el DataSet tenemos 4 posibles formatos de fecha\n",
        "- dd-MM-yyyy\n",
        "- yyyy-MM-dd\n",
        "- yyyy/MM/dd\n",
        "- dd/MM/yyyy\n",
        "\n",
        "Por lo que pasaremos primero a definir que esas columnas son de tipo `Date` y posteriormente le asignamos el formato que queremos.\n",
        "En este dataset nos encontraremos con un valor `9999-99-99` por lo que lo transformaremos de valor `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8CMenIEYjDJ8"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import when, col, to_date\n",
        "\n",
        "# Columnas con fechas\n",
        "col_fechas = ['FECHA_ACTUALIZACION','FECHA_INGRESO','FECHA_SINTOMAS','FECHA_DEF']\n",
        "\n",
        "for columna in col_fechas:\n",
        "    df = df.withColumn(columna,\n",
        "                        when(col(columna).rlike(r'^\\d{2}-\\d{2}-\\d{4}$'),\n",
        "                             to_date(col(columna), 'dd-MM-yyyy'))\n",
        "                       .when(col(columna).rlike(r'^\\d{4}-\\d{2}-\\d{2}$'),\n",
        "                             to_date(col(columna), 'yyyy-MM-dd'))\n",
        "                       .when(col(columna).rlike(r'^\\d{2}/\\d{2}/\\d{4}$'),\n",
        "                             to_date(col(columna), 'dd/MM/yyyy'))\n",
        "                       .when(col(columna).rlike(r'^\\d{4}/\\d{2}/\\d{2}$'),\n",
        "                             to_date(col(columna), 'yyyy/MM/dd'))\n",
        "                       .otherwise(None))\n",
        "\n",
        "for columna in col_fechas:\n",
        "    df = df.withColumn(columna, to_date(columna, 'yyyy-MM-dd'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yMj8FBaxUXO"
      },
      "source": [
        "Pasaremos a utilizar otro filtro que nos ayudara a ordenar los datos. Esto lo haremos con la columna `FECHA_ACTUALIZACION`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYRUAXRKxyGg"
      },
      "outputs": [],
      "source": [
        "df = df.sort(\"FECHA_ACTUALIZACION\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnB8HeiWx5w0"
      },
      "source": [
        "Mostraremos la primera entrada y la ultima para confirmar que el Dataframe fue ordenado correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "5xGAG5odAuK6",
        "outputId": "e42892b7-0b9b-407f-de1c-356d666fe813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:KeyboardInterrupt while sending command.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\", line 511, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f69586b927dc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mBob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     def _show_string(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m_show_string\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/clientserver.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                 \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLGUeifGwVA5"
      },
      "source": [
        "Dentro de la documentacion https://www.gob.mx/salud/documentos/datos-abiertos-152127 nos especifican que existe una categoria que lo llaman `\"SI_NO\"`, los cuales incluye:\n",
        "- 1 = SI\n",
        "- 2 = NO\n",
        "- 97 = NO APLICA\n",
        "- 98 = SE IGNORA\n",
        "- 99 = NO ESPECIFICADO\n",
        "\n",
        "Al tratarse de un modelo que se utilizara en un futuro para entrenar un modelo predictivo tenemos que considerar en eliminar los valores diferentes a partir de interpretarlos como otros, es decir las variables '`NO APLICA`', '`SE IGNORA`' y '`NO ESPECIFICADO`' vamos a interpretarlas directamente como '`NO`'; para despues pasar a una convención el cual es trabajar con 0 y 1, lo que pasaremos el 2 a 0.\n",
        "\n",
        "Revisando la documentacion, columnas que pertenecen a la categoria `\"SI_NO\"`:\n",
        "- INTUBADO\n",
        "- NEUMONIA\n",
        "- HABLA_LENGUA_INDIG\n",
        "- INDIGENA\n",
        "- DIABETES\n",
        "- EPOC\n",
        "- ASMA\n",
        "- INMUSUPR\n",
        "- HIPERTENSION\n",
        "- OTRAS_COM\n",
        "- CARDIOVASCULAR\n",
        "- OBESIDAD\n",
        "- RENAL_CRONICA\n",
        "- TABAQUISMO\n",
        "- OTRO_CASO\n",
        "- TOMA_MUESTRA_LAB\n",
        "- TOMA_MUESTRA_ANTIGENO\n",
        "- MIGRANTE\n",
        "- UCI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DA1SJOID0KhC"
      },
      "outputs": [],
      "source": [
        "columnas_modificar = [\"INTUBADO\",\n",
        "                    \"NEUMONIA\",\n",
        "                    \"HABLA_LENGUA_INDIG\",\n",
        "                    \"INDIGENA\",\n",
        "                    \"DIABETES\",\n",
        "                    \"EPOC\",\n",
        "                    \"ASMA\",\n",
        "                    \"INMUSUPR\",\n",
        "                    \"HIPERTENSION\",\n",
        "                    \"CARDIOVASCULAR\",\n",
        "                    \"OBESIDAD\",\n",
        "                    \"RENAL_CRONICA\",\n",
        "                    \"TABAQUISMO\",\n",
        "                    \"OTRO_CASO\",\n",
        "                    \"OTRA_COM\",\n",
        "                    \"TOMA_MUESTRA_LAB\",\n",
        "                    \"TOMA_MUESTRA_ANTIGENO\",\n",
        "                    \"MIGRANTE\",\n",
        "                    \"ORIGEN\",\n",
        "                    \"EMBARAZO\",\n",
        "                    \"UCI\"]\n",
        "\n",
        "for columna in columnas_modificar:\n",
        "    df = df.withColumn(columna,\n",
        "                       when(df[columna] == 2, 0)\n",
        "                       .otherwise(df[columna]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XPFSPbY2knX"
      },
      "source": [
        "Tambien necesitamos modificar la variable de '`SEXO`', estos vienen de la siguiente manera:\n",
        "- 1 = Mujer\n",
        "- 2 = Hombre\n",
        "- 99 = No especificado\n",
        "\n",
        "Los casos de no especificados los pasaremos a `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYI5ny0S4qeF"
      },
      "outputs": [],
      "source": [
        "df = df.withColumnRenamed(\"SEXO\", \"SEXO_MUJER\")\n",
        "df = df.withColumn(\"SEXO_MUJER\",\n",
        "                   when(df[\"SEXO_MUJER\"] == 2, 0)\n",
        "                   .otherwise(df[\"SEXO_MUJER\"]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWlJ3jp65MTT"
      },
      "source": [
        "Para evitar confusiones en futuras consultas vamos a especificar más nuestra columna, pasaremos de llamarlo \"SEXO\" a \"SEXO_MUJER\" para que cuando el valor sea 1 sepamos que ese paciente era Mujer y si es 0 no es mujer por ende es Hombre."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FdNZyLJ51SC"
      },
      "outputs": [],
      "source": [
        "df = df.withColumnRenamed(\"SEXO\", \"SEXO_MUJER\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfNdR83nDewV"
      },
      "source": [
        "Haremos lo mismo en las columnas que lo necesiten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2lDyQGwDisF"
      },
      "outputs": [],
      "source": [
        "df = df.withColumnRenamed(\"ORIGEN\", \"USMER\")\n",
        "df = df.withColumn(\"USMER\",\n",
        "                   when(df[\"USMER\"] == 2, 0)\n",
        "                   .otherwise(df[\"USMER\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GBG5AJSEBvk"
      },
      "outputs": [],
      "source": [
        "df = df.withColumnRenamed(\"TIPO_PACIENTE\", \"HOSPITALIZADO\")\n",
        "df = df.withColumn(\"HOSPITALIZADO\",\n",
        "                   when(df[\"HOSPITALIZADO\"] == 1, 0)\n",
        "                   .when(df[\"HOSPITALIZADO\"] == 2, 1)\n",
        "                   .otherwise(df[\"HOSPITALIZADO\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ77IzDoEqeo"
      },
      "outputs": [],
      "source": [
        "df = df.withColumnRenamed(\"NACIONALIDAD\", \"EXTRANJERA\")\n",
        "df = df.withColumn(\"EXTRANJERA\",\n",
        "                   when(df[\"EXTRANJERA\"] == 1, 0)\n",
        "                   .when(df[\"EXTRANJERA\"] == 2, 1)\n",
        "                   .otherwise(df[\"EXTRANJERA\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nANjnHbFruN"
      },
      "source": [
        "Podemos generalizar las demas columnas ya que los valores 97, 98, 99 siempre demuestran un valor nulo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dbtVhBGFqVm"
      },
      "outputs": [],
      "source": [
        "columnas_a_ignorar = [\"EDAD\",\"FECHA_ACTUALIZACION\",\n",
        "                      \"FECHA_INGRESO\",\"FECHA_SINTOMAS\",\n",
        "                      \"FECHA_DEF\", \"ID_REGISTRO\"]\n",
        "\n",
        "columnas_a_modificar = [elemento for elemento in df.columns\n",
        "                        if elemento not in columnas_a_ignorar]\n",
        "\n",
        "# Aplicar el reemplazo para cada columna excepto \"edad\" y columnas con fechas\n",
        "for col_name in columnas_a_modificar:\n",
        "    df = df.withColumn(col_name,\n",
        "                       when((col(col_name).isin([97, 98, 99])), None)\n",
        "                       .otherwise(col(col_name)))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.csv(\"/content/covid_20.csv\", header=True)"
      ],
      "metadata": {
        "id": "NOVcqUxCqioQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "8pzFvZJjq3zA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2CtNTFigpEg4i2ebA6EWm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}